# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: proto/inference.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'proto/inference.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x15proto/inference.proto\x12\rdcb.inference\"\xd7\x01\n\x10InferenceRequest\x12\x12\n\nrequest_id\x18\x01 \x01(\t\x12\x12\n\nmodel_name\x18\x02 \x01(\t\x12\x11\n\tinput_ids\x18\x03 \x03(\x03\x12\x12\n\nmax_length\x18\x04 \x01(\x05\x12\x10\n\x08priority\x18\x05 \x01(\x05\x12\x17\n\x0f\x65nable_kv_prune\x18\x06 \x01(\x08\x12\x12\n\nkv_prune_k\x18\x07 \x01(\x05\x12\x1a\n\x12\x65nable_speculative\x18\x08 \x01(\x08\x12\x19\n\x11speculative_steps\x18\t \x01(\x05\"G\n\x11InferenceResponse\x12\x12\n\nrequest_id\x18\x01 \x01(\t\x12\r\n\x05token\x18\x02 \x01(\x03\x12\x0f\n\x07is_last\x18\x03 \x01(\x08\"A\n\x0c\x42\x61tchRequest\x12\x31\n\x08requests\x18\x01 \x03(\x0b\x32\x1f.dcb.inference.InferenceRequest\"D\n\rBatchResponse\x12\x33\n\tresponses\x18\x01 \x03(\x0b\x32 .dcb.inference.InferenceResponse2\xb1\x01\n\x10InferenceService\x12T\n\x0bStreamInfer\x12\x1f.dcb.inference.InferenceRequest\x1a .dcb.inference.InferenceResponse(\x01\x30\x01\x12G\n\nBatchInfer\x12\x1b.dcb.inference.BatchRequest\x1a\x1c.dcb.inference.BatchResponseBM\n\x19\x63om.yourorg.dcb.inferenceZ0github.com/yourorg/dcb-inference/proto;inferenceb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'proto.inference_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'\n\031com.yourorg.dcb.inferenceZ0github.com/yourorg/dcb-inference/proto;inference'
  _globals['_INFERENCEREQUEST']._serialized_start=41
  _globals['_INFERENCEREQUEST']._serialized_end=256
  _globals['_INFERENCERESPONSE']._serialized_start=258
  _globals['_INFERENCERESPONSE']._serialized_end=329
  _globals['_BATCHREQUEST']._serialized_start=331
  _globals['_BATCHREQUEST']._serialized_end=396
  _globals['_BATCHRESPONSE']._serialized_start=398
  _globals['_BATCHRESPONSE']._serialized_end=466
  _globals['_INFERENCESERVICE']._serialized_start=469
  _globals['_INFERENCESERVICE']._serialized_end=646
# @@protoc_insertion_point(module_scope)
